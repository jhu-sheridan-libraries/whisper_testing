# Hugging Face API token
# 1. Go to https://huggingface.co/settings/tokens to create a token
# 2. IMPORTANT: You MUST accept the terms for the models you use.
#    - Diarization: https://huggingface.co/pyannote/speaker-diarization-3.1
#    - Segmentation: https://huggingface.co/pyannote/segmentation-3.0
# 3. Use a token with at least READ permission.
HF_TOKEN=your_token_here

# How Precise do you want the transcripts?
# lower    = int8: typically fastest, can run on CPU or GPU, might require specific hardware support for best performance.
# medium   = float16:faster on compatible GPUs, requires CUDA (if no CUDA then defaults to auto).
# standard = float32: often slower but more precise.
# auto     = automatically determine which is going to output the best results.
# lower, medium, standard, auto
PRECISSION=auto

# Fine Tuning
BEAM_SIZE=5

# CPU threads thresholds from 0.75 to 0.5 typically.
CPU_THRESHOLD=0.75

# Minimal GPU worker count
MIN_WORKERS=2

# Which faster-whisper version to use; (latest, gpu)
WHISPER_VER=latest

# Transcription model: faster-whisper, openai-whisper
TRANSCRIPTION_MODEL=faster-whisper

# Temperature for transcription. Higher values make the output more random.
TEMPERATURE=0.0

# Initial prompt to guide the model.
# INITIAL_PROMPT="This is a technical discussion about software development."

# --- Performance Settings ---
# Number of CPU threads to use (0 for optimal).
CPU_THREADS=0

# Docker container limit
CPU_LIMIT=5.6

# Number of workers for transcription (0 for optimal).
NUM_WORKERS=0

# GPU device to use for transcription.
GPU_DEVICE=0

# CPU usage threshold for determining optimal threads (e.g., 0.75 = 75% of cores).
CPU_THRESHOLD=0.75

# Minimum number of workers for GPU transcription.
MIN_WORKERS=2

# --- Diarization Settings ---
# Diarization pipeline: pyannote/speaker-diarization-3.1, pyannote/speaker-diarization
DIARIZATION_PIPELINE="pyannote/speaker-diarization-3.1"

# Expected number of speakers. Leave blank to auto-detect.
# NUM_SPEAKERS=2

# Voice Activity Detection (VAD) level: 0 (off), 1 (low), 2 (medium), 3 (high)
VAD_LEVEL=2

# Timeout in seconds for the diarization process.
DIARIZATION_TIMEOUT=1800

# --- Output Settings ---
# Output format: vtt, srt, txt, json
OUTPUT_FORMAT=vtt

# Optional: Specify a default output path.
# OUTPUT_PATH=/output/my_default_transcript.vtt

# --- Language and Task Settings ---
# Language code for transcription (e.g., en, es, fr). Leave blank for auto-detection.
# LANGUAGE=en

# Task to perform: transcribe, translate
TASK=transcribe

VTT_MAX_CHARS=35